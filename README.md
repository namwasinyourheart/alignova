# Alignova: Aligning LLMs for better reliability, safety, and adherence to human intent.