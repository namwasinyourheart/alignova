{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nos.environ['HUGGINGFACEHUB_API_TOKEN'] = user_secrets.get_secret(\"HUGGINGFACEHUB_API_TOKEN\")\nos.environ['WANDB_API_KEY'] = user_secrets.get_secret(\"WANDB_API_KEY \")\n\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HUGGINGFACEHUB_API_TOKEN\")\nlogin(token = hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T04:57:36.368788Z","iopub.execute_input":"2025-03-19T04:57:36.369349Z","iopub.status.idle":"2025-03-19T04:57:37.932296Z","shell.execute_reply.started":"2025-03-19T04:57:36.369305Z","shell.execute_reply":"2025-03-19T04:57:37.930880Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"<iframe\n\tsrc=\"https://namfam-ask-ati.hf.space\"\n\tframeborder=\"0\"\n\twidth=\"850\"\n\theight=\"450\"\n></iframe>\n","metadata":{}},{"cell_type":"code","source":"%%writefile requirements.txt\ngit+https://github.com/huggingface/transformers\ndatasets==3.2.0\npeft==0.10.0\ntrl==0.8.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T04:57:37.941811Z","iopub.execute_input":"2025-03-19T04:57:37.942205Z","iopub.status.idle":"2025-03-19T04:57:37.966879Z","shell.execute_reply.started":"2025-03-19T04:57:37.942171Z","shell.execute_reply":"2025-03-19T04:57:37.965399Z"}},"outputs":[{"name":"stdout","text":"Writing requirements.txt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -r requirements.txt -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T04:57:38.038906Z","iopub.execute_input":"2025-03-19T04:57:38.039435Z","iopub.status.idle":"2025-03-19T04:58:23.537709Z","shell.execute_reply.started":"2025-03-19T04:57:38.039395Z","shell.execute_reply":"2025-03-19T04:58:23.536249Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.1/245.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport pandas as pd\n\ntqdm.pandas()\n\nfrom transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\nfrom datasets import load_dataset\n\nfrom trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\nfrom trl.core import LengthSampler\n\nfrom peft import get_peft_model, LoraConfig, TaskType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T04:58:23.539324Z","iopub.execute_input":"2025-03-19T04:58:23.539665Z","iopub.status.idle":"2025-03-19T04:58:56.177690Z","shell.execute_reply.started":"2025-03-19T04:58:23.539634Z","shell.execute_reply":"2025-03-19T04:58:56.176318Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"config = PPOConfig(\n    model_name=\"lvwerra/gpt2-imdb\",\n    learning_rate=1.41e-5,\n    log_with=\"wandb\",\n)\n\n# sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": 16}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:06:54.944527Z","iopub.execute_input":"2025-03-19T05:06:54.944929Z","iopub.status.idle":"2025-03-19T05:06:54.952359Z","shell.execute_reply.started":"2025-03-19T05:06:54.944900Z","shell.execute_reply":"2025-03-19T05:06:54.950904Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import wandb\n\nwandb.init()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:02:23.291075Z","iopub.execute_input":"2025-03-19T05:02:23.291628Z","iopub.status.idle":"2025-03-19T05:02:39.421701Z","shell.execute_reply.started":"2025-03-19T05:02:23.291575Z","shell.execute_reply":"2025-03-19T05:02:39.420221Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamfam\u001b[0m (\u001b[33mparacetamol\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250319_050232-9gndfxhu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/paracetamol/uncategorized/runs/9gndfxhu' target=\"_blank\">rare-dragon-1</a></strong> to <a href='https://wandb.ai/paracetamol/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/paracetamol/uncategorized' target=\"_blank\">https://wandb.ai/paracetamol/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/paracetamol/uncategorized/runs/9gndfxhu' target=\"_blank\">https://wandb.ai/paracetamol/uncategorized/runs/9gndfxhu</a>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paracetamol/uncategorized/runs/9gndfxhu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7fa6e7879360>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def build_dataset(\n    config, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8\n):\n    \"\"\"\n    Build dataset for training. This builds the dataset from `load_dataset`, one should\n    customize this function to train the model on its own dataset.\n\n    Args:\n        dataset_name (`str`):\n            The name of the dataset to be loaded.\n\n    Returns:\n        dataloader (`torch.utils.data.DataLoader`):\n            The dataloader for the dataset.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n    tokenizer.pad_token = tokenizer.eos_token\n    # load imdb with datasets\n    ds = load_dataset(dataset_name, split=\"train\")\n    ds = ds.rename_columns({\"text\": \"review\"})\n    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n\n    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n\n    def tokenize(sample):\n        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n        return sample\n\n    ds = ds.map(tokenize, batched=False)\n    ds.set_format(type=\"torch\")\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:02:39.423602Z","iopub.execute_input":"2025-03-19T05:02:39.424137Z","iopub.status.idle":"2025-03-19T05:02:39.432770Z","shell.execute_reply.started":"2025-03-19T05:02:39.424087Z","shell.execute_reply":"2025-03-19T05:02:39.431543Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"dataset = build_dataset(config)\n\n\ndef collator(data):\n    return dict((key, [d[key] for d in data]) for key in data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:02:46.443053Z","iopub.execute_input":"2025-03-19T05:02:46.443461Z","iopub.status.idle":"2025-03-19T05:03:33.767882Z","shell.execute_reply.started":"2025-03-19T05:02:46.443428Z","shell.execute_reply":"2025-03-19T05:03:33.766222Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"397970419f1040d2b3d2ba89325e7820"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/577 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6486d442f80745fd8a0996d1e964a573"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4d804d385794ef8843dbc3e6b24a949"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de80bf15b1ce451abe5e433bd06f06a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"168529a435df44bbadb2bd9ff82d6aaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f23b9a871b4249eb9bc8d53dc90df561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2865409ef5d44c4aada51276706acb75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9979483c6ea4b79a4b4e12cf9067270"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4b0a620d20495785fd7693b43b34be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b73617252f64378a56a2b0b5644db86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c56f7190463409192300ea3d7adf984"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf343457afcd47a79931a8d582590e84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7515f10cd8a4e1e8294993c815758c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/24895 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40a9242ba23f4df99f2a27578b14b67e"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained(config.model_name)\n\n\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    inference_mode=False,\n    r=32,\n    lora_alpha=32,\n    lora_dropout=0.1,\n)\n\npeft_model = get_peft_model(model, peft_config)\npeft_model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:03:33.769680Z","iopub.execute_input":"2025-03-19T05:03:33.770149Z","iopub.status.idle":"2025-03-19T05:03:38.590463Z","shell.execute_reply.started":"2025-03-19T05:03:33.770101Z","shell.execute_reply":"2025-03-19T05:03:38.587581Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7d07ffffece47a186626d4c7a0e7436"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d68da994c9fb461292b4f4788c6d318d"}},"metadata":{}},{"name":"stdout","text":"trainable params: 1,179,648 || all params: 125,619,456 || trainable%: 0.939064725769868\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model = AutoModelForCausalLMWithValueHead.from_pretrained(peft_model, is_trainable=True)\n\nref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\ntokenizer = AutoTokenizer.from_pretrained(config.model_name)\n\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:03:38.611123Z","iopub.execute_input":"2025-03-19T05:03:38.612427Z","iopub.status.idle":"2025-03-19T05:03:41.057784Z","shell.execute_reply.started":"2025-03-19T05:03:38.612384Z","shell.execute_reply":"2025-03-19T05:03:41.056190Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/trl/models/modeling_base.py:328: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = loading_func(filename if not use_safe else safe_filename, **load_kwargs)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"ppo_trainer = PPOTrainer(\n    config, model, ref_model, tokenizer, dataset=dataset, data_collator=collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:04:03.683199Z","iopub.execute_input":"2025-03-19T05:04:03.683693Z","iopub.status.idle":"2025-03-19T05:04:03.742090Z","shell.execute_reply.started":"2025-03-19T05:04:03.683657Z","shell.execute_reply":"2025-03-19T05:04:03.740745Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"device = ppo_trainer.accelerator.device\nif ppo_trainer.accelerator.num_processes == 1:\n    device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a `pipeline` bug\nsentiment_pipe = pipeline(\n    \"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\", device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:04:50.211886Z","iopub.execute_input":"2025-03-19T05:04:50.212357Z","iopub.status.idle":"2025-03-19T05:04:58.546855Z","shell.execute_reply.started":"2025-03-19T05:04:50.212319Z","shell.execute_reply":"2025-03-19T05:04:58.545264Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3d9d45bc06346d3b6fbc0ac02cc6c5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e2bdb066a9d48dd8098ff3f8c1fdd71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"430073e395e04cddb3e14554576b1c1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48deec21112640f7b58868c1a1c414be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"090d1a339016478582259584fe396b9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69f5aa16fe554678a9d1d33e4deefedb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb0628e663574d4585c00e6925ff5648"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": 16}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:08:22.750784Z","iopub.execute_input":"2025-03-19T05:08:22.751306Z","iopub.status.idle":"2025-03-19T05:08:22.758658Z","shell.execute_reply.started":"2025-03-19T05:08:22.751250Z","shell.execute_reply":"2025-03-19T05:08:22.757405Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"text = \"this movie was really bad!!\"\nsentiment_pipe(text, **sent_kwargs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:08:23.098759Z","iopub.execute_input":"2025-03-19T05:08:23.099199Z","iopub.status.idle":"2025-03-19T05:08:23.144969Z","shell.execute_reply.started":"2025-03-19T05:08:23.099167Z","shell.execute_reply":"2025-03-19T05:08:23.143850Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"[[{'label': 'NEGATIVE', 'score': 2.335048198699951},\n  {'label': 'POSITIVE', 'score': -2.7265758514404297}]]"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"text = \"this movie was really good!!\"\nsentiment_pipe(text, **sent_kwargs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:08:23.421310Z","iopub.execute_input":"2025-03-19T05:08:23.421777Z","iopub.status.idle":"2025-03-19T05:08:23.467121Z","shell.execute_reply.started":"2025-03-19T05:08:23.421734Z","shell.execute_reply":"2025-03-19T05:08:23.465924Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"[[{'label': 'NEGATIVE', 'score': -2.294790267944336},\n  {'label': 'POSITIVE', 'score': 2.557039976119995}]]"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"gen_kwargs = {\n    \"min_length\": -1,\n    \"top_k\": 0.0,\n    \"top_p\": 1.0,\n    \"do_sample\": True,\n    \"pad_token_id\": tokenizer.eos_token_id,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:08:36.223549Z","iopub.execute_input":"2025-03-19T05:08:36.224109Z","iopub.status.idle":"2025-03-19T05:08:36.231699Z","shell.execute_reply.started":"2025-03-19T05:08:36.224066Z","shell.execute_reply":"2025-03-19T05:08:36.230001Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"output_min_length = 4\noutput_max_length = 16\noutput_length_sampler = LengthSampler(output_min_length, output_max_length)\n\n\ngeneration_kwargs = {\n    \"min_length\": -1,\n    \"top_k\": 0.0,\n    \"top_p\": 1.0,\n    \"do_sample\": True,\n    \"pad_token_id\": tokenizer.eos_token_id,\n}\ndo y\nnum_steps = 10\n\nfor epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n    if epoch >= num_steps:\n        break\n\n    query_tensors = batch[\"input_ids\"]\n\n    #### Get response from gpt2\n    response_tensors = []\n    for query in query_tensors:\n        gen_len = output_length_sampler()\n        generation_kwargs[\"max_new_tokens\"] = gen_len\n        response = ppo_trainer.generate(query, **generation_kwargs)\n        response_tensors.append(response.squeeze()[-gen_len:])\n    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n\n    #### Compute sentiment score\n    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n    rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n\n    #### Run PPO step\n    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n\n    print(f'objective/kl: {stats[\"objective/kl\"]}')\n    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n    print(\"-\".join(\"\" for x in range(100)))\n\n    ppo_trainer.log_stats(stats, batch, rewards)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:09:13.950365Z","iopub.execute_input":"2025-03-19T05:09:13.950803Z","iopub.status.idle":"2025-03-19T05:35:41.294342Z","shell.execute_reply.started":"2025-03-19T05:09:13.950767Z","shell.execute_reply":"2025-03-19T05:35:41.292528Z"}},"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.0\nppo/returns/mean: [0.23505962]\nppo/policy/advantages_mean: [5.3809748e-09]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"2it [05:41, 169.71s/it]","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.0012171671260148287\nppo/returns/mean: [0.21986592]\nppo/policy/advantages_mean: [-6.5278885e-09]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"3it [08:13, 161.49s/it]","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.0020485538989305496\nppo/returns/mean: [0.33081955]\nppo/policy/advantages_mean: [-1.2817637e-08]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"4it [10:50, 159.71s/it]","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.003495934419333935\nppo/returns/mean: [0.22087021]\nppo/policy/advantages_mean: [5.4819544e-09]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"5it [13:41, 163.87s/it]","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.004939259961247444\nppo/returns/mean: [0.11188509]\nppo/policy/advantages_mean: [1.5454802e-08]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"6it [16:17, 161.02s/it]","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.003437031526118517\nppo/returns/mean: [0.18264383]\nppo/policy/advantages_mean: [6.849433e-09]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"7it [18:51, 158.93s/it]","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.003687117248773575\nppo/returns/mean: [-0.01243018]\nppo/policy/advantages_mean: [-2.198728e-08]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"8it [21:25, 157.30s/it]","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.005033315625041723\nppo/returns/mean: [0.0771886]\nppo/policy/advantages_mean: [-2.9024871e-09]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"9it [23:49, 153.23s/it]","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.010240523144602776\nppo/returns/mean: [0.15799445]\nppo/policy/advantages_mean: [-3.0299028e-09]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"10it [26:27, 158.73s/it]","output_type":"stream"},{"name":"stdout","text":"objective/kl: 0.005905399564653635\nppo/returns/mean: [0.21424198]\nppo/policy/advantages_mean: [-1.6313884e-08]\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"#### get a batch from the dataset\nbs = 16\ngame_data = dict()\ndataset.set_format(\"pandas\")\ndf_batch = dataset[:].sample(bs)\ngame_data[\"query\"] = df_batch[\"query\"].tolist()\nquery_tensors = df_batch[\"input_ids\"].tolist()\n\nresponse_tensors_ref, response_tensors = [], []\n\n#### get response from gpt2 and gpt2_ref\nfor i in range(bs):\n    gen_len = output_length_sampler()\n    output = ref_model.generate(\n        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n        max_new_tokens=gen_len,\n        **gen_kwargs\n    ).squeeze()[-gen_len:]\n    response_tensors_ref.append(output)\n    output = model.generate(\n        input_ids=torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n        max_new_tokens=gen_len,\n        **gen_kwargs\n    ).squeeze()[-gen_len:]\n    response_tensors.append(output)\n\n#### decode responses\ngame_data[\"response (before)\"] = [\n    tokenizer.decode(response_tensors_ref[i]) for i in range(bs)\n]\ngame_data[\"response (after)\"] = [\n    tokenizer.decode(response_tensors[i]) for i in range(bs)\n]\n\n#### sentiment analysis of query/response pairs before/after\ntexts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\ngame_data[\"rewards (before)\"] = [\n    output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)\n]\n\ntexts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\ngame_data[\"rewards (after)\"] = [\n    output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)\n]\n\n# store results in a dataframe\ndf_results = pd.DataFrame(game_data)\ndf_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T05:51:39.956304Z","iopub.execute_input":"2025-03-19T05:51:39.957032Z","iopub.status.idle":"2025-03-19T05:51:55.492499Z","shell.execute_reply.started":"2025-03-19T05:51:39.956975Z","shell.execute_reply":"2025-03-19T05:51:55.491111Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                           query  \\\n0              the only scenes w   \n1                     This is an   \n2                A dedicated fan   \n3   Painfully bad Christmas film   \n4               OK, I am blessed   \n5            To put it simply, I   \n6          Andy Goldsworthy is a   \n7         I went into this movie   \n8                      I gave it   \n9            This is actually an   \n10              I found the film   \n11              The Great Caruso   \n12      Haunted by a secret, Ben   \n13               Any film in the   \n14          This video guide was   \n15                 For the first   \n\n                                    response (before)  \\\n0   idescreen (well, a couple of. Also its under-s...   \n1                          example typified by dances   \n2   , I urge you to rent this movie. It's perfect ...   \n3                               , the plot is totally   \n4    that the Blaxploitation fans will sue me for ...   \n5                     'm not surprised out loud about   \n6                    really good actor because I love   \n7    thinking 'That sounds cool'. I really did. Th...   \n8                            a 5.9 out of 100 because   \n9                     unusual split in Soviet society   \n10   fascinating, not because I had an innate non-...   \n11              The Great Caruso' (2008)<|endoftext|>   \n12   gets chopped up by a preacher, but he forgive...   \n13   320Camera Derby had nice camera angles too & ...   \n14                              written by Kyle Smith   \n15                        five minutes you can't help   \n\n                                     response (after)  rewards (before)  \\\n0   ah-aahs in this picture, before you read throu...         -0.717310   \n1                                  obvious rip-off of          1.067269   \n2   . I know I didn't really like Denmark when I s...          2.096747   \n3                  bad Christmas film...<|endoftext|>         -2.846969   \n4    and uplifted to see Poussey, obviously making...         -0.278830   \n5                          'm really glad I did watch         -0.766335   \n6                              stunner and one of the          2.328285   \n7    expecting it will get cancellation fees in th...          1.357731   \n8                      a try, one thing that it never          1.314584   \n9                            amazing movie, filmed by          0.782727   \n10   to be an uncomfortable experience to watch, I...          1.985693   \n11   axe (20 plus extras) Xyped Furthermore, Nicol...          1.189676   \n12   Gardner, produced on a very small budget, wit...          1.166140   \n13   early 20th century that doesn't try to be cool (         -1.544899   \n14                             supposedly running, it          0.354532   \n15                  few seconds to time brick through         -1.748167   \n\n    rewards (after)  \n0          0.275434  \n1         -1.669199  \n2          1.862923  \n3         -2.655954  \n4          2.263268  \n5          1.825589  \n6          0.013276  \n7         -0.698931  \n8          0.510754  \n9          2.734681  \n10         0.318586  \n11        -1.089433  \n12         1.671652  \n13         0.492783  \n14        -1.306385  \n15         0.534188  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query</th>\n      <th>response (before)</th>\n      <th>response (after)</th>\n      <th>rewards (before)</th>\n      <th>rewards (after)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the only scenes w</td>\n      <td>idescreen (well, a couple of. Also its under-s...</td>\n      <td>ah-aahs in this picture, before you read throu...</td>\n      <td>-0.717310</td>\n      <td>0.275434</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This is an</td>\n      <td>example typified by dances</td>\n      <td>obvious rip-off of</td>\n      <td>1.067269</td>\n      <td>-1.669199</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A dedicated fan</td>\n      <td>, I urge you to rent this movie. It's perfect ...</td>\n      <td>. I know I didn't really like Denmark when I s...</td>\n      <td>2.096747</td>\n      <td>1.862923</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Painfully bad Christmas film</td>\n      <td>, the plot is totally</td>\n      <td>bad Christmas film...&lt;|endoftext|&gt;</td>\n      <td>-2.846969</td>\n      <td>-2.655954</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OK, I am blessed</td>\n      <td>that the Blaxploitation fans will sue me for ...</td>\n      <td>and uplifted to see Poussey, obviously making...</td>\n      <td>-0.278830</td>\n      <td>2.263268</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>To put it simply, I</td>\n      <td>'m not surprised out loud about</td>\n      <td>'m really glad I did watch</td>\n      <td>-0.766335</td>\n      <td>1.825589</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Andy Goldsworthy is a</td>\n      <td>really good actor because I love</td>\n      <td>stunner and one of the</td>\n      <td>2.328285</td>\n      <td>0.013276</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>I went into this movie</td>\n      <td>thinking 'That sounds cool'. I really did. Th...</td>\n      <td>expecting it will get cancellation fees in th...</td>\n      <td>1.357731</td>\n      <td>-0.698931</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>I gave it</td>\n      <td>a 5.9 out of 100 because</td>\n      <td>a try, one thing that it never</td>\n      <td>1.314584</td>\n      <td>0.510754</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>This is actually an</td>\n      <td>unusual split in Soviet society</td>\n      <td>amazing movie, filmed by</td>\n      <td>0.782727</td>\n      <td>2.734681</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>I found the film</td>\n      <td>fascinating, not because I had an innate non-...</td>\n      <td>to be an uncomfortable experience to watch, I...</td>\n      <td>1.985693</td>\n      <td>0.318586</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>The Great Caruso</td>\n      <td>The Great Caruso' (2008)&lt;|endoftext|&gt;</td>\n      <td>axe (20 plus extras) Xyped Furthermore, Nicol...</td>\n      <td>1.189676</td>\n      <td>-1.089433</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Haunted by a secret, Ben</td>\n      <td>gets chopped up by a preacher, but he forgive...</td>\n      <td>Gardner, produced on a very small budget, wit...</td>\n      <td>1.166140</td>\n      <td>1.671652</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Any film in the</td>\n      <td>320Camera Derby had nice camera angles too &amp; ...</td>\n      <td>early 20th century that doesn't try to be cool (</td>\n      <td>-1.544899</td>\n      <td>0.492783</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>This video guide was</td>\n      <td>written by Kyle Smith</td>\n      <td>supposedly running, it</td>\n      <td>0.354532</td>\n      <td>-1.306385</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>For the first</td>\n      <td>five minutes you can't help</td>\n      <td>few seconds to time brick through</td>\n      <td>-1.748167</td>\n      <td>0.534188</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}